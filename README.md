# Analyse de structure de canop√©e et classification de peuplements √† partir de donn√©es LiDAR

**Niveau** : Master 2  
**Dur√©e** : 3 s√©ances de 3h  
**Pr√©-requis** : notions de base en R, connaissance g√©n√©rale des √©cosyst√®mes forestiers  
**Logiciels utilis√©s** : CloudCompare, R (packages `lidR`, `terra`, `sf`, `dplyr`, `SciViews`, `xfun`)  
**Encadrant** : Herrault Pierre-Alexis
**Donn√©es** : fournies (fichiers `.LAS`, MNT, grille d‚Äô√©chantillonnage shapefile)  

---

## Objectif g√©n√©ral du module

Ce module appartient √† l'UE Traitement de Nuages de Points et dure 12h. Les objectifs seront de comprendre et mettre en ≈ìuvre une approche compl√®te d‚Äôanalyse LiDAR pour la **caract√©risation et la classification de peuplements forestiers**, depuis l‚Äôexploration du nuage de points jusqu‚Äô√† la production d‚Äôune carte de classes structurales.

---

## Organisation des s√©ances

### üü© S√©ance 1 ‚Äî Exploration et familiarisation avec les donn√©es LiDAR 

**Objectif :** Comprendre la nature et la structure des donn√©es LiDAR a√©riennes, visualiser et manipuler un nuage de points, et savoir les importer dans R.

Les donn√©es dont accessibles ici : https://seafile.unistra.fr/d/b82497f4534d4e24a3cf/

#### 1. Introduction 

Un point de cours rapide vous sera propos√© afin de reprendre les points suivants : 

- Rappel du principe du LiDAR a√©roport√© : hauteur, intensit√©, retour laser, sol / v√©g√©tation.  
- Pr√©sentation des objectifs du module : de la donn√©e brute √† la classification structurale de la v√©g√©tation 
- Pr√©sentation rapide du papier de **Fahey et al. (2022)** pour introduire l‚Äôid√©e de typologie structurale bas√©e sur des variables LiDAR. 

#### 2. Visualisation dans CloudCompare 

Votre premier objectif consiste √† prendre en main une tuile .las et √† l'importer dans CloudCompare. Prenez le temps d'explorer la donn√©e, ses sp√©cificit√©s, son h√©t√©rog√©n√©it√©. 

- **Ouverture d‚Äôune tuile LiDAR (.LAS)** : rep√©rage des canaux (X, Y, Z, Intensity, ReturnNumber, Classification).  
- **Colorisation du nuage** : par altitude, intensit√© et nombre de retours. NB : n'h√©sitez pas √† visualiser la distribution des variables et √† modifier les bornes min-max pour mieux saisir l'amplitude des valeurs. 
- **Affichage de sections et coupes verticales** pour comprendre la stratification de la canop√©e. Par exemple, visualisez les points dans les deux m√®tres sup√©rieurs. Ceux situ√©s dans le premier m√®tre en partant du sol. Pour ces derniersq, qu'observez vous ?   
- **Exercice pratique : suppression manuelle de points parasites** (ex. points isol√©s, erreurs de sol).  
  - Pour cela, utilisez l‚Äôoutil ‚Äúsegment‚Äù et export du nuage nettoy√© au format `.las`.

#### 3. Importation dans R 

Dans un second temps, nous allons passer sur R pour visualiser cette m√™me donn√©e. L'objectif est √† terme d'utiliser cet environnement pour faciliter l'extraction de variables √† partir de packages d√©j√† d√©velopp√©s. 

```r
library(lidR)
library(sf)
library(terra)
library(dplyr)

ctg <- readLAScatalog("data/LAS/")    ## votre chemin vers les tuiles LAS
mnt <- rast("data/mnt_coteaux_hiatus.tif")  ## votre chemin vers le MNT
grid <- st_read("data/plot_fabas.shp")   ## votre chemin vers la grille de plots

las <- readLAS("data/example_tile.las")    ## lire votre tuile 
head(las@data)                             ## visualiser la structure de la table attributaire
summary(las@data$Z)                        ## checker les statistiques de hauteur

las_canopy <- filter_poi(las, Z > 1 & ReturnNumber == 1)       ## filtrer les points constituant la canop√©e

plot(las, color = "Intensity") ## Reproduisez la m√™me ligne en appliquant une palette viridis √† la hauteur des points
```
---

### üüß S√©ance 2 ‚Äî Extraction des m√©triques structurales √† partir du nuage de points 

**Objectif :** Extraire des variables d√©crivant la structure de la canop√©e √† partir de donn√©es LiDAR normalis√©es, sur la base du script fourni.

#### 1. Introduction 

- Nous allons premi√®rement revenir sur la proposition de classification structurale propos√©e par **Fahey et al. (2022)**. Quels sont les trois dimensions propos√©es ? En quoi refl√®tent-elles la structure globale d'un environnement forestier ?
- Dans le script fourni, rep√©rez les 3 groupes de variables suivants. 
  
  - Variables de hauteur 
  - Variables li√©es √† l'h√©t√©rog√©n√©it√© horizontale 
  - Variables li√©es √† la distribution verticale 
 
- Pour chacune des variables utilis√©es pour chaque groupe, dites en quoi elles peuvent √™tre compl√©mentaires ? Quel int√©r√™t peut-il y avoir √† calculer ces diff√©rentes variables ?

#### 2. Mise en place du script

Pour cette section, l'objectif va √™tre de faire fonctionner le script pour calculer les variables sur la totalit√© de vos plots (plot_fabas)

- Explication et ex√©cution du script fourni pas √† pas (voir fichier `extraction_metrics.R`).
- Calcul des m√©triques par maille : hauteur, rugosit√©, couverture, densit√© de scan, etc.
- V√©rification de la sortie `results_canopy_metrics.csv` :
```r
data <- read.csv("results_canopy_metrics.csv")
summary(data)
```
- Tracez la distibution de chaque variable √† l'aide de boxplots ou d'histogramme. Qu'observez vous sur la distribution statistique des variables calcul√©es ?

#### 3. Discussion finale 

- Interpr√©tation des variables.  
- Lien avec les typologies structurales de Fahey (axes continus de hauteur, h√©t√©rog√©n√©it√© verticale et horizontale).
  
---

### üü¶ S√©ance 3 ‚Äî Classification et spatialisation des peuplements

**Objectif :** R√©aliser une classification des peuplements selon leurs caract√©ristiques structurales et repr√©senter les r√©sultats spatialement.

#### 1. Pr√©paration des donn√©es

Avant de proc√©der √† la classification, importons les donn√©es dont nous aurons besoin √† savoir les donn√©es produites ainsi que les plots pour r√©-aggr√©ger spatialement les donn√©es class√©es. 

```r
data <- read.csv("results_canopy_metrics.csv")
grid <- st_read("data/plot_fabas.shp")
grid_data <- grid %>% left_join(data, by = "Id")
```

#### 2. Classification 

Pour la classification des donn√©es plots, nous proc√©derons diff√©remment de l'article que vous avez lu. Une simple ACP sera premi√®rement appliqu√©e pour r√©duire la dimensionnalit√© du jeu de donn√©es puis nous utiliserons deuxi√®mement une classification 
ascendante hi√©rachique pour classer les plots au sein du plan factoriel. 

```r
library(FactoMineR)   # pour PCA et HCPC
library(factoextra)   # pour visualisations
library(dplyr)        # pour manipulation des donn√©es si besoin

# Charger les donn√©es
data <- read.csv("results_canopy_metrics.csv")

# V√©rifier les donn√©es
head(data)
str(data)


# 2. ACP sur les variables (en excluant la colonne ID si pr√©sente)
res.pca <- PCA(data[, -1],      # exclure colonne ID
               scale.unit = TRUE,  # standardiser les variables
               graph = FALSE)      # pas de graph par d√©faut


# 3. Visualisation des r√©sultats de l'ACP

# Biplot g√©n√©ral
fviz_pca_biplot(res.pca, 
                repel = TRUE,   # √©viter le chevauchement des labels
                col.var = "blue", 
                col.ind = "gray") 

# Cercle des corr√©lations (qualit√© de repr√©sentation des variables)
fviz_pca_var(res.pca, col.var = "contrib") + 
  scale_color_gradient2(low = "white", mid = "yellow", high = "red", midpoint = 5)

# Contribution des variables aux axes principaux
fviz_contrib(res.pca, choice = "var", axes = 1, top = 10) # top 10 variables sur axe 1
fviz_contrib(res.pca, choice = "var", axes = 2, top = 10)

# 4. Classification hi√©rarchique sur composantes principales (HCPC)

res.hcpc <- HCPC(res.pca, nb.clust = -1, graph = FALSE)  # nb.clust=-1 permet de laisser HCPC choisir automatiquement
fviz_dend(res.hcpc, rect = TRUE, show_labels = TRUE)   # revisualiser le dendrogramme pour ajuster
res.hcpc <- HCPC(res.pca, nb.clust = 4, graph = FALSE)  # nb.clust=-1 permet de laisser HCPC choisir automatiquement

```
- Interpr√©tation des classes : moyennes de variables, signification structurale.  
- Lien avec les types de canop√©es selon Fahey.

#### 3. Spatialisation et validation
```r
# 5. Visualisation des clusters

# Dendrogramme pour voir la hi√©rarchie
fviz_dend(res.hcpc, rect = TRUE, show_labels = TRUE)

# Projeter le r√©sultat de clustering dans l'espace de la PCA
fviz_cluster(res.hcpc, 
             repel = TRUE, 
             palette = "jco", 
             geom = "point", 
             ellipse.type = "convex")

# Description des clusters (moyennes des variables par cluster)
res.hcpc$desc.var$quanti    # variables quantitatives
res.hcpc$desc.ind$dist      # individus les plus caract√©ristiques

# Repr√©sentez sous la forme d'histogramme les r√©sultats obtenus et donnez une premi√®re lecture des classes de structure

# 6. Extra : ajouter les clusters au dataframe original
data$cluster <- factor(res.hcpc$data.clust$clust)

# V√©rifier les clusters
table(data$cluster)
head(data)
write.csv(data,"canopy_clusters.csv")

# Joignez les r√©sultats produits au shapefile de vos plots dans QGIS. Gr√¢ce aux r√©sultats de
# obtenus pr√©c√©demment, d√©crivez les classes obtenus et remettez les en perspective dans le cas
# de la for√™t de Fabas
```
- Observez la distribution spatiale des classes. Appliquez une orthophoto IRC (=> gr√¢ce au flux de l'IGN). Commentez la coh√©rence entre la classification et la texture de l'orthophotographie. 
- Comparez ensuite votre classification avec des cartes externes issus des Plans de Gestion Simple (cf Documentation). 
- Notez vos r√©sultats

---

## R√©f√©rences

- **Fahey, R. T. et al. (2019)**. *Defining a spectrum of integrative trait-based vegetation canopy structural types.*  
- **Roussel, J.-R. et al. (2020)**. *lidR: An R package for analysis of Airborne Laser Scanning (ALS) data.* *Remote Sensing of Environment, 251, 112061.*
